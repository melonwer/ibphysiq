# Example .env file for IB Physics Question Generator
# Copy this to .env.local and fill in your credentials. Do NOT commit .env.local.

# Lightning AI (preferred for shared deployments)
# Get your API credentials from Lightning AI dashboard
LIT_API_URL=https://your-lightning-ai-deployment-url.com/predict
LIT_API_TOKEN=your_lightning_ai_api_token_here

# Optional: use the local server-side proxy instead of direct LIT calls
# When set, the app will call this URL (e.g. http://localhost:3000/api/predict-proxy)
#LIT_PROXY_URL=http://localhost:3000/api/predict-proxy

# Hugging Face (alternative provider)
# Get your API key from https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=hf_your_huggingface_api_key_here

# Model selection
LLAMA_MODEL_ID=d4ydy/ib-physics-question-generator

# Google Gemini API Key (optional - for refinement)
# Get your API key from https://console.cloud.google.com/
# GOOGLE_API_KEY=your_google_gemini_api_key_here

# OpenRouter API Key (recommended - free DeepSeek model)
# Get your API key from https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-v1-your_openrouter_api_key_here

# Default refinement provider
REFINEMENT_PROVIDER=openrouter

# Local text-generation UI (text-generation-webui, etc.)
LOCAL_TGI_URL=http://localhost:5000

# Pipeline configuration flags
ENABLE_REFINEMENT=true
FALLBACK_TO_ORIGINAL=true
REQUIRE_MINIMUM_QUALITY=false

# Environment
NODE_ENV=development